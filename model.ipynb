{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydub noisereduce json-tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from json_tricks import dump, load\n",
    "\n",
    "from pydub import AudioSegment, effects\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'emotions' list fix for classification purposes:\n",
    "#     Classification values start from 0, Thus an 'n = n-1' operation has been executed for both RAVDESS and TESS databases:\n",
    "def emotionfix(e_num):\n",
    "    if e_num == \"01\":   return 0 # neutral\n",
    "    elif e_num == \"02\": return 1 # calm\n",
    "    elif e_num == \"03\": return 2 # happy\n",
    "    elif e_num == \"04\": return 3 # sad\n",
    "    elif e_num == \"05\": return 4 # angry\n",
    "    elif e_num == \"06\": return 5 # fear\n",
    "    elif e_num == \"07\": return 6 # disgust\n",
    "    else:               return 7 # suprised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum samples count for padding purposes.\n",
    "\n",
    "sample_lengths = []\n",
    "folder_path = 'Audio_Speech_Actors_01-24'\n",
    "\n",
    "for subdir, dirs, files in os.walk(folder_path):\n",
    "  for file in files: \n",
    "    x, sr = librosa.load(path = os.path.join(subdir,file), sr = None)\n",
    "    xt, index = librosa.effects.trim(x, top_db=30)\n",
    "     \n",
    "    sample_lengths.append(len(xt))\n",
    "\n",
    "print('Maximum sample length:', np.max(sample_lengths))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sample length: 204288\n"
     ]
    }
   ],
   "source": [
    "# Maximum samples count for padding purposes.\n",
    "\n",
    "sample_lengths = []\n",
    "folder_path = 'RAVDESS/'\n",
    "\n",
    "for subdir, dirs, files in os.walk(folder_path):\n",
    "  for file in files: \n",
    "    x, sr = librosa.load(path = os.path.join(subdir,file), sr = None)\n",
    "    xt, index = librosa.effects.trim(x, top_db=30)\n",
    "     \n",
    "    sample_lengths.append(len(xt))\n",
    "\n",
    "print('Maximum sample length:', np.max(sample_lengths))                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# Initialize data lists\n",
    "rms = []\n",
    "zcr = []\n",
    "mfcc = []\n",
    "emotions = []\n",
    "\n",
    "# Initialize variables\n",
    "total_length = 173056 # desired frame length for all of the audio samples.\n",
    "frame_length = 2048\n",
    "hop_length = 512\n",
    "\n",
    "folder_path = 'RAVDESS/' \n",
    "\n",
    "for subdir, dirs, files in os.walk(folder_path):\n",
    "  for file in files: \n",
    "\n",
    "    # Fetch the sample rate.\n",
    "      _, sr = librosa.load(path = os.path.join(subdir,file), sr = None) # sr (the sample rate) is used for librosa's MFCCs. '_' is irrelevant.\n",
    "    # Load the audio file.\n",
    "      rawsound = AudioSegment.from_file(os.path.join(subdir,file)) \n",
    "    # Normalize the audio to +5.0 dBFS.\n",
    "      normalizedsound = effects.normalize(rawsound, headroom = 0) \n",
    "    # Transform the normalized audio to np.array of samples.\n",
    "      normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
    "    # Trim silence from the beginning and the end.\n",
    "      xt, index = librosa.effects.trim(normal_x, top_db=30)\n",
    "      #print(file,\"\\t\", len(xt), \"\\t\", rawsound.dBFS, \"\\t\", normalizedsound.dBFS) #--QA purposes if needed-- \n",
    "    # Pad for duration equalization.\n",
    "      padded_x = np.pad(xt, max(0, (total_length - len(xt))), 'constant')\n",
    "    # Noise reduction.\n",
    "      final_x = nr.reduce_noise(padded_x, sr=sr) #updated 03/03/22\n",
    "       \n",
    "   # Features extraction \n",
    "      f1 = librosa.feature.rms(y=final_x, frame_length=frame_length, hop_length=hop_length)# Energy - Root Mean Square   \n",
    "      f2 = librosa.feature.zero_crossing_rate(y=final_x , frame_length=frame_length, hop_length=hop_length, center=True) # ZCR      \n",
    "      f3 = librosa.feature.mfcc(y=final_x, sr=sr, n_mfcc=13, hop_length = hop_length) # MFCC\n",
    "      \n",
    "   # Emotion extraction from the different databases\n",
    "      name = file[6:8]                      \n",
    "\n",
    "   # Filling the data lists  \n",
    "      rms.append(f1)\n",
    "      zcr.append(f2)\n",
    "      mfcc.append(f3)\n",
    "      emotions.append(emotionfix(name)) \n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Running time: {(toc - tic)/60:0.4f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 951. MiB for an array with shape (1440, 1, 173056) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m f_rms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(rms)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m f_rms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mswapaxes(f_rms,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m f_zcr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(zcr)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m f_zcr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mswapaxes(f_zcr,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      9\u001b[0m f_mfccs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(mfcc)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 951. MiB for an array with shape (1440, 1, 173056) and data type float32"
     ]
    }
   ],
   "source": [
    "# Adjusting features shape to the 3D format: (batch, timesteps, feature)\n",
    "\n",
    "# making all in equal dimensions\n",
    "\n",
    "f_rms = np.asarray(rms).astype('float32')\n",
    "f_rms = np.swapaxes(f_rms,1,2)\n",
    "f_zcr = np.asarray(zcr).astype('float32')\n",
    "f_zcr = np.swapaxes(f_zcr,1,2)\n",
    "f_mfccs = np.asarray(mfcc).astype('float32')\n",
    "f_mfccs = np.swapaxes(f_mfccs,1,2)\n",
    "\n",
    "print('ZCR shape:',f_zcr.shape)\n",
    "print('RMS shape:',f_rms.shape)\n",
    "print('MFCCs shape:',f_mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis1: axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Adjusting features shape to the 3D format: (batch, timesteps, feature)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m f_rms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(rms)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m f_rms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mswapaxes(f_rms,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m f_zcr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(zcr)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m f_zcr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mswapaxes(f_zcr,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mswapaxes\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:594\u001b[0m, in \u001b[0;36mswapaxes\u001b[1;34m(a, axis1, axis2)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_swapaxes_dispatcher)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mswapaxes\u001b[39m(a, axis1, axis2):\n\u001b[0;32m    552\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m    Interchange two axes of an array.\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m \n\u001b[0;32m    593\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswapaxes\u001b[39m\u001b[38;5;124m'\u001b[39m, axis1, axis2)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis1: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# Adjusting features shape to the 3D format: (batch, timesteps, feature)\n",
    "\n",
    "f_rms = np.asarray(rms).astype('float32')\n",
    "f_rms = np.swapaxes(f_rms,1,2)\n",
    "f_zcr = np.asarray(zcr).astype('float32')\n",
    "f_zcr = np.swapaxes(f_zcr,1,2)\n",
    "f_mfccs = np.asarray(mfcc).astype('float32')\n",
    "f_mfccs = np.swapaxes(f_mfccs,1,2)\n",
    "\n",
    "print('ZCR shape:',f_zcr.shape)\n",
    "print('RMS shape:',f_rms.shape)\n",
    "print('MFCCs shape:',f_mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Concatenating all features to 'X' variable.\n",
    "X = np.concatenate((f_zcr, f_rms, f_mfccs), axis=2)\n",
    "\n",
    "# Preparing 'Y' as a 2D shaped variable.\n",
    "Y = np.asarray(emotions).astype('int8')\n",
    "Y = np.expand_dims(Y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RBF Kernel SVM to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model.fit(X_train.reshape(X_train.shape[0], -1), y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Flatten\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the RandomForestClassifier to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the XGBoost Classifier to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "# Initialize and train the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(units=128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    LSTM(units=64),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, to_categorical(y_train), epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, to_categorical(y_test))\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the CNN model\n",
    "def create_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv1D(32, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "    # Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(8, activation='softmax'))  # Assuming 8 emotions\n",
    "\n",
    "    return model\n",
    "\n",
    "# Input shape should match the shape of the concatenated features\n",
    "input_shape = X.shape[1:]\n",
    "\n",
    "# Create the CNN model\n",
    "cnn_model = create_cnn_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = cnn_model.fit(X, Y, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = cnn_model.evaluate(X, Y)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for the CNN model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Make predictions\n",
    "y_pred = np.argmax(cnn_model.predict(X), axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(Y, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "labels = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprised']\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Save the CNN model\n",
    "cnn_model.save(\"emotion_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Load the CNN model\n",
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model(\"emotion_cnn_model.h5\")\n",
    "\n",
    "# # Evaluate the loaded model\n",
    "# loss, accuracy = loaded_model.evaluate(X, Y)\n",
    "# print(\"Accuracy on the test set:\", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Record audio\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# Record audio\n",
    "duration = 3  # seconds\n",
    "sample_rate = 22050  # sample rate\n",
    "channels = 1  # number of audio channels\n",
    "filename = 'output.wav'\n",
    "\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels, dtype='float32')\n",
    "sd.wait()\n",
    "sf.write(filename, audio, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the audio file\n",
    "import numpy as np\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "\n",
    "# Load the audio file\n",
    "x, sr = librosa.load('Audio_Speech_Actors_01-24\\Actor_10\\\\03-01-01-01-01-01-10.wav', sr=None)\n",
    "\n",
    "# Trim silence\n",
    "xt, index = librosa.effects.trim(x, top_db=30)\n",
    "\n",
    "# Pad the audio file\n",
    "total_length = 173056\n",
    "padded_x = np.pad(xt, (0, max(total_length-len(xt), 0)), 'constant')\n",
    "\n",
    "# listen to the audio\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(padded_x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Noise reduction\n",
    "final_x = nr.reduce_noise(padded_x, sr=sr)\n",
    "\n",
    "#listen to the audio\n",
    "ipd.Audio(final_x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "import librosa\n",
    "\n",
    "# Extract RMS feature\n",
    "rms = librosa.feature.rms(y=final_x, frame_length=2048, hop_length=512)\n",
    "\n",
    "# Extract ZCR feature\n",
    "zcr = librosa.feature.zero_crossing_rate(final_x, frame_length=2048, hop_length=512, center=True)\n",
    "\n",
    "# Extract MFCCs\n",
    "mfcc = librosa.feature.mfcc(y=final_x, sr=sr, n_mfcc=13, hop_length=512)\n",
    "\n",
    "# Ensure all arrays have the same shape\n",
    "rms = np.resize(rms, (1, 1440))\n",
    "zcr = np.resize(zcr, (1, 1440))\n",
    "mfcc = np.resize(mfcc, (13, 1440))\n",
    "\n",
    "# Concatenate the features\n",
    "X = np.concatenate((zcr, rms, mfcc), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# load the CNN model\n",
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model(\"emotion_cnn_model.h5\")\n",
    "\n",
    "# Transpose the input data to match the expected input shape of the model\n",
    "X_transposed = np.transpose(X, (1, 0))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = np.argmax(loaded_model.predict(np.expand_dims(X_transposed, axis=0)), axis=1)\n",
    "\n",
    "# Map the predicted label to the corresponding emotion\n",
    "emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprised']\n",
    "emotion = emotions[y_pred[0]]\n",
    "print(\"Predicted emotion:\", emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# predict emotion from in real-time\n",
    "\n",
    "# define a function to predict the emotion from a given audio file\n",
    "\n",
    "def predict_emotion(filename):\n",
    "    # Load the audio file\n",
    "    x, sr = librosa.load(filename, sr=None)\n",
    "\n",
    "    # Trim silence\n",
    "    xt, index = librosa.effects.trim(x, top_db=30)\n",
    "\n",
    "    # Pad the audio file\n",
    "    total_length = 173056\n",
    "    padded_x = np.pad(xt, (0, max(total_length-len(xt), 0)), 'constant')\n",
    "\n",
    "    # Noise reduction\n",
    "    final_x = nr.reduce_noise(padded_x, sr=sr)\n",
    "\n",
    "    # Extract features\n",
    "    rms = librosa.feature.rms(y=final_x, frame_length=2048, hop_length=512)\n",
    "    zcr = librosa.feature.zero_crossing_rate(final_x, frame_length=2048, hop_length=512, center=True)\n",
    "    mfcc = librosa.feature.mfcc(y=final_x, sr=sr, n_mfcc=13, hop_length=512)\n",
    "\n",
    "    # Ensure all arrays have the same shape\n",
    "    rms = np.resize(rms, (1, 1440))\n",
    "    zcr = np.resize(zcr, (1, 1440))\n",
    "    mfcc = np.resize(mfcc, (13, 1440))\n",
    "\n",
    "    # Concatenate the features\n",
    "    X = np.concatenate((zcr, rms, mfcc), axis=0)\n",
    "\n",
    "    # Transpose the input data to match the expected input shape of the model\n",
    "    X_transposed = np.transpose(X, (1, 0))\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = np.argmax(loaded_model.predict(np.expand_dims(X_transposed, axis=0)), axis=0)\n",
    "\n",
    "    # Map the predicted label to the corresponding emotion\n",
    "    emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprised']\n",
    "    emotion = emotions[y_pred[0]]\n",
    "    return emotion\n",
    "\n",
    "# Record audio\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# Record audio\n",
    "duration = 3  # seconds\n",
    "sample_rate = 22050  # sample rate\n",
    "channels = 1  # number of audio channels\n",
    "filename = 'recording.wav'\n",
    "\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels, dtype='float32')\n",
    "sd.wait()\n",
    "sf.write(filename, audio, sample_rate)\n",
    "\n",
    "# Predict the emotion\n",
    "emotion = predict_emotion(filename)\n",
    "print(\"Predicted emotion:\", emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for your message...\n",
      "Done recording..\n",
      "Printing the message..\n",
      "Your message:this is too scary\n",
      "{'neg': 0.516, 'neu': 0.484, 'pos': 0.0, 'compound': -0.4939}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import speech_recognition as sr\n",
    "reco=sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    reco.adjust_for_ambient_noise(source,duration=1)\n",
    "    print('Waiting for your message...')\n",
    "    recordedaudio=reco.listen(source)\n",
    "    print('Done recording..')\n",
    "\n",
    "try:\n",
    "    print('Printing the message..')\n",
    "    text=reco.recognize_google(recordedaudio,language='en-US')\n",
    "    print('Your message:{}'.format(text))\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "#Sentiment analysis\n",
    "\n",
    "Statement=[str(text)]\n",
    "analyser=SentimentIntensityAnalyzer()\n",
    "for i in Statement:\n",
    "    v=analyser.polarity_scores(i)\n",
    "    print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
